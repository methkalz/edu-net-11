import { serve } from 'https://deno.land/std@0.208.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';
import { corsHeaders } from '../_shared/cors.ts';
import * as pdfjsLib from 'npm:pdfjs-dist@4.0.379/legacy/build/pdf.mjs';

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      throw new Error('Missing authorization header');
    }

    const supabase = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_ANON_KEY')!,
      { global: { headers: { Authorization: authHeader } } }
    );

    const { filePath, bucket } = await req.json();

    if (!filePath || !bucket) {
      throw new Error('Missing required parameters: filePath and bucket');
    }

    console.log(`ğŸ“„ Extracting text from: ${bucket}/${filePath}`);

    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† Storage
    const { data: fileData, error: downloadError } = await supabase.storage
      .from(bucket)
      .download(filePath);

    if (downloadError) {
      console.error('Download error:', downloadError);
      throw new Error(`Failed to download file: ${downloadError.message}`);
    }

    // ØªØ­ÙˆÙŠÙ„ Blob Ø¥Ù„Ù‰ ArrayBuffer
    const arrayBuffer = await fileData.arrayBuffer();
    const pdfBytes = new Uint8Array(arrayBuffer);
    console.log(`ğŸ“¦ PDF size: ${pdfBytes.length} bytes`);

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF
    const rawText = await extractTextFromPDF(pdfBytes);
    console.log(`âœ… Raw text extracted: ${rawText.length} characters`);

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ (Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰)
    const cleanedText = cleanText(rawText);
    console.log(`ğŸ§¹ Cleaned text: ${cleanedText.length} characters`);

    // ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©)
    const normalizedText = advancedArabicNormalization(cleanedText);
    console.log(`ğŸ”¤ Normalized text: ${normalizedText.length} characters`);

    // Ø­Ø³Ø§Ø¨ Hash Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ·Ø¨Ù‘Ø¹
    const textHash = await calculateHash(normalizedText);
    
    // Ø­Ø³Ø§Ø¨ Simhash Ù„Ù„ÙƒØ´Ù Ø§Ù„Ø³Ø±ÙŠØ¹
    const simhashValue = simhash(normalizedText);
    
    // Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
    const wordCount = countWords(cleanedText);
    
    // ØªÙˆÙ„ÙŠØ¯ N-Grams (3-character)
    const ngrams3 = Array.from(generateNGrams(normalizedText, 3)).slice(0, 10000);
    
    console.log(`ğŸ“Š Stats: ${wordCount} words, hash: ${textHash.substring(0, 16)}...`);
    console.log(`First 200 chars: ${cleanedText.substring(0, 200)}`);

    return new Response(
      JSON.stringify({
        success: true,
        rawText: rawText.substring(0, 5000), // Ù„Ù„Ø£Ø±Ø´ÙØ© ÙÙ‚Ø· (5000 Ø­Ø±Ù)
        cleanedText, // Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ø¸ÙŠÙ Ù„Ù„ØªØ®Ø²ÙŠÙ†
        normalizedText, // Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ·Ø¨Ù‘Ø¹ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        text: cleanedText, // Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…
        hash: textHash,
        simhash: simhashValue.toString(),
        wordCount,
        ngrams3, // N-grams Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        metadata: {
          extraction_method: 'pdfjs-dist-v4',
          text_length: cleanedText.length,
          normalized_length: normalizedText.length,
          extractedAt: new Date().toISOString(),
        }
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  } catch (error) {
    console.error('âŒ Error in pdf-extract-text:', error);
    return new Response(
      JSON.stringify({
        success: false,
        error: error instanceof Error ? error.message : String(error),
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});

// Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PDF.js
async function extractTextFromPDF(pdfBytes: Uint8Array): Promise<string> {
  try {
    console.log(`Starting PDF text extraction, file size: ${pdfBytes.length} bytes`);
    
    // ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDF
    const loadingTask = pdfjsLib.getDocument({
      data: pdfBytes,
      useSystemFonts: true,
      standardFontDataUrl: 'https://cdn.jsdelivr.net/npm/pdfjs-dist@4.0.379/standard_fonts/',
    });
    
    const pdf = await loadingTask.promise;
    const numPages = pdf.numPages;
    console.log(`PDF loaded successfully, total pages: ${numPages}`);
    
    let fullText = '';
    
    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„ ØµÙØ­Ø©
    for (let pageNum = 1; pageNum <= numPages; pageNum++) {
      try {
        const page = await pdf.getPage(pageNum);
        const textContent = await page.getTextContent();
        
        // ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø§Ù„ØµÙØ­Ø©
        const pageText = textContent.items
          .map((item: any) => {
            // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Øµ
            if (item.str && typeof item.str === 'string') {
              return item.str;
            }
            return '';
          })
          .filter((text: string) => text.trim().length > 0)
          .join(' ');
        
        if (pageText.trim().length > 0) {
          fullText += pageText + '\n\n';
          if (pageNum % 10 === 0) {
            console.log(`  âœ“ Processed ${pageNum}/${numPages} pages`);
          }
        }
      } catch (pageError) {
        console.warn(`âš ï¸ Error on page ${pageNum}:`, pageError);
        continue;
      }
    }
    
    if (!fullText || fullText.trim().length === 0) {
      console.warn('âš ï¸ Primary extraction returned empty, trying fallback...');
      return extractTextFallback(pdfBytes);
    }
    
    console.log(`Total extracted text length: ${fullText.length} characters`);
    return fullText;
  } catch (error) {
    console.error('âŒ PDF.js extraction failed:', error);
    return extractTextFallback(pdfBytes);
  }
}

// Fallback: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ù„Ø¨Ø§ÙŠØªØ§Øª
function extractTextFallback(pdfBytes: Uint8Array): string {
  console.log('ğŸ”„ Using fallback text extraction...');
  
  try {
    const decoder = new TextDecoder('utf-8', { fatal: false });
    const rawText = decoder.decode(pdfBytes);
    
    const textMatches = rawText.match(/\(([^)]+)\)/g);
    if (textMatches && textMatches.length > 0) {
      const extractedText = textMatches
        .map(match => match.slice(1, -1))
        .filter(text => text.length > 2)
        .join(' ');
      
      if (extractedText.trim().length > 0) {
        console.log(`Fallback extraction successful: ${extractedText.length} characters`);
        return extractedText;
      }
    }
  } catch (fallbackError) {
    console.error('Fallback extraction also failed:', fallbackError);
  }
  
  return '';
}

// ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ - Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
function cleanText(text: string): string {
  const technicalKeywords = [
    'obj', 'endobj', 'stream', 'endstream',
    'Type', 'Font', 'Catalog', 'Pages', 'Page',
    'Parent', 'Resources', 'Contents', 'MediaBox',
    'TrueType', 'BaseFont', 'Encoding', 'ToUnicode',
    'Length', 'Filter', 'FlateDecode', 'Subtype',
    'FirstChar', 'LastChar', 'Widths', 'FontDescriptor'
  ];
  
  return text
    // ØªØ·Ø¨ÙŠØ¹ Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø·Ø±
    .replace(/\r\n/g, '\n')
    .replace(/\r/g, '\n')
    // Ø¥Ø²Ø§Ù„Ø© Ø£Ø­Ø±Ù ØºÙŠØ± Ù…Ø±Ø¦ÙŠØ© ÙˆØ®Ø§ØµØ©
    .replace(/[\u0000-\u001F\u007F-\u009F]/g, ' ')
    .replace(/\u200B/g, '')
    .replace(/\uFEFF/g, '')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    .replace(/\t/g, ' ')
    .replace(/[ ]{2,}/g, ' ')
    .replace(/\n{3,}/g, '\n\n')
    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©
    .replace(/\b(obj|endobj|stream|endstream|xref|trailer|startxref)\b/gi, '')
    // ØªÙ‚Ø³ÙŠÙ… ÙˆØªØµÙÙŠØ©
    .split(/\s+/)
    .filter(word => {
      if (!word || word.length < 2) return false;
      if (technicalKeywords.includes(word)) return false;
      if (word.startsWith('/')) return false;
      if (/^\d+$/.test(word)) return false;
      return true;
    })
    .join(' ')
    .trim();
}

// ØªØ·Ø¨ÙŠØ¹ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ - Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
function advancedArabicNormalization(text: string): string {
  return text
    .toLowerCase()
    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„
    .replace(/[\u064B-\u065F\u0670\u0640]/g, '')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù Ø¨Ø¬Ù…ÙŠØ¹ Ø£Ø´ÙƒØ§Ù„Ù‡Ø§
    .replace(/[Ø¢Ø£Ø¥Ù±]/g, 'Ø§')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‡Ù…Ø²Ø©
    .replace(/[Ø¤Ø¦]/g, 'Ø¡')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙŠØ§Ø¡
    .replace(/[Ù‰ÙŠ]/g, 'ÙŠ')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø© ÙˆØ§Ù„Ù‡Ø§Ø¡
    .replace(/Ø©/g, 'Ù‡')
    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒØ´ÙŠØ¯Ø©
    .replace(/Ù€/g, '')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù‡Ù†Ø¯ÙŠØ© Ø¥Ù„Ù‰ ASCII
    .replace(/[Ù -Ù©]/g, (d) => String.fromCharCode(d.charCodeAt(0) - 1632 + 48))
    .replace(/[Û°-Û¹]/g, (d) => String.fromCharCode(d.charCodeAt(0) - 1776 + 48))
    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©
    .replace(/[^\u0600-\u06FFa-zA-Z0-9\s]/g, ' ')
    // ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    .replace(/\s+/g, ' ')
    .trim();
}

// Ø­Ø³Ø§Ø¨ SHA-256 Hash
async function calculateHash(text: string): Promise<string> {
  const encoder = new TextEncoder();
  const data = encoder.encode(text);
  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
}

// Ø­Ø³Ø§Ø¨ Simhash (Ù„Ù„ÙƒØ´Ù Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¹Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ØªØ§Ù…/Ø´Ø¨Ù‡ Ø§Ù„ØªØ§Ù…)
function simhash(text: string): bigint {
  const words = text.split(/\s+/).filter(w => w.length > 2);
  const vector = new Array(64).fill(0);
  
  for (const word of words) {
    const hash = hashString(word);
    for (let i = 0; i < 64; i++) {
      if (hash & (1n << BigInt(i))) {
        vector[i]++;
      } else {
        vector[i]--;
      }
    }
  }
  
  let result = 0n;
  for (let i = 0; i < 64; i++) {
    if (vector[i] > 0) {
      result |= (1n << BigInt(i));
    }
  }
  
  return result;
}

// FNV-1a Hash Ù„Ù„Ù†ØµÙˆØµ
function hashString(str: string): bigint {
  const FNV_PRIME = 0x100000001b3n;
  let hash = 0xcbf29ce484222325n;
  
  for (let i = 0; i < str.length; i++) {
    hash ^= BigInt(str.charCodeAt(i));
    hash = BigInt.asUintN(64, hash * FNV_PRIME);
  }
  
  return hash;
}

// ØªÙˆÙ„ÙŠØ¯ Character N-Grams
function generateNGrams(text: string, n: number = 3): Set<string> {
  const ngrams = new Set<string>();
  const normalized = text.replace(/\s+/g, '');
  
  for (let i = 0; i <= normalized.length - n; i++) {
    ngrams.add(normalized.substring(i, i + n));
  }
  
  return ngrams;
}

// Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
function countWords(text: string): number {
  return text.split(/\s+/).filter(word => word.length > 0).length;
}
