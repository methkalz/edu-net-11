import { serve } from 'https://deno.land/std@0.208.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';
import { corsHeaders } from '../_shared/cors.ts';
import * as fuzzball from 'https://esm.sh/fuzzball@2.2.2';

interface FileToCompare {
  fileName: string;
  filePath: string;
  fileText: string;
  fileHash: string;
  filePages: number;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      throw new Error('Missing authorization header');
    }

    const startTime = Date.now();

    const supabase = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    );

    const {
      files,
      gradeLevel,
      comparisonType,
      userId,
      schoolId,
    } = await req.json();

    if (!files || files.length === 0) {
      throw new Error('No files provided for comparison');
    }

    console.log(`ğŸ“¦ Starting batch comparison for ${files.length} files (Grade ${gradeLevel})`);

    const batchId = crypto.randomUUID();
    const results = [];

    // Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø£ÙˆÙ„Ø§Ù‹
    console.log('ğŸ“¤ Step 1: Adding all files to repository...');
    const repositoryFileIds: Map<string, string> = new Map();
    
    for (const file of files) {
      try {
        // Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹
        const addResult = await supabase.functions.invoke('pdf-add-to-repository', {
          body: {
            tempFilePath: file.filePath,
            fileName: file.fileName,
            extractedText: file.fileText,
            textHash: file.fileHash,
            pageCount: file.filePages,
            fileSize: 0,
            gradeLevel,
            projectType: comparisonType,
            uploadedBy: userId,
            schoolId,
            deleteTemp: false, // Ù†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
          },
        });

        if (addResult.data?.success && addResult.data?.data?.id) {
          repositoryFileIds.set(file.fileHash, addResult.data.data.id);
          console.log(`âœ… Added ${file.fileName} to repository`);
        }
      } catch (error) {
        console.error(`âŒ Error adding ${file.fileName} to repository:`, error);
      }
    }

    // Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© (Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©) Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„Ù
    console.log('ğŸ”„ Step 2: Internal comparison...');
    const internalComparisons: Map<string, any[]> = new Map();

    if (files.length > 1) {
      for (let i = 0; i < files.length; i++) {
        const file1 = files[i];
        const file1Comparisons = [];

        for (let j = 0; j < files.length; j++) {
          if (i === j) continue; // ØªØ®Ø·ÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ù†ÙØ³Ù‡

          const file2 = files[j];

          // ÙØ­Øµ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ØªØ§Ù… (Hash)
          if (file1.fileHash === file2.fileHash) {
            file1Comparisons.push({
              matched_file_name: file2.fileName,
              similarity_score: 1.0,
              similarity_method: 'hash_exact_match',
              flagged: true,
            });
            continue;
          }

          // Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ
          const text1 = preprocessText(file1.fileText, file1.fileText.split(/\s+/).length);
          const text2 = preprocessText(file2.fileText, file2.fileText.split(/\s+/).length);

          const similarity = calculateSimilarity(text1, text2);

          // âœ… Ø¥ØµÙ„Ø§Ø­ 6: Ø®ÙØ¶ Ø§Ù„Ø¹ØªØ¨Ø© Ù…Ù† 0.30 Ø¥Ù„Ù‰ 0.25
          if (similarity > 0.25) {
            file1Comparisons.push({
              matched_file_name: file2.fileName,
              similarity_score: Math.round(similarity * 100) / 100,
              similarity_method: 'text_comparison',
              flagged: similarity >= 0.70,
            });
          }
        }

        // ØªØ±ØªÙŠØ¨ ÙˆØ£Ø®Ø° Ø£Ø¹Ù„Ù‰ 5
        file1Comparisons.sort((a, b) => b.similarity_score - a.similarity_score);
        internalComparisons.set(file1.fileHash, file1Comparisons.slice(0, 5));
      }
    }

    // Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©)
    console.log('ğŸ—„ï¸ Step 3: Repository comparison...');
    
    // Ø¬Ù„Ø¨ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ø­Ø§Ù„ÙŠØ§Ù‹)
    const uploadedHashes = files.map((f: FileToCompare) => f.fileHash);
    
    // âœ… Ø¥ØµÙ„Ø§Ø­ 1: Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø«Ù… Ø§Ù„ÙÙ„ØªØ±Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹
    const { data: allRepositoryFiles, error: repoError } = await supabase
      .from('pdf_comparison_repository')
      .select('*')
      .eq('grade_level', gradeLevel)
      .eq('project_type', comparisonType)
      .order('created_at', { ascending: false });

    if (repoError) {
      console.error('âŒ Error fetching repository files:', repoError);
    }

    // ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ ÙŠØ¯ÙˆÙŠØ§Ù‹ (Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹)
    const repositoryFiles = allRepositoryFiles?.filter(
      rf => !uploadedHashes.includes(rf.text_hash)
    ) || [];

    console.log(`ğŸ“š Repository query results:`, {
      total: allRepositoryFiles?.length || 0,
      afterFilter: repositoryFiles.length,
      gradeLevel,
      comparisonType,
      excludedHashes: uploadedHashes.length,
    });

    // Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
    if (repositoryFiles.length > 0) {
      console.log(`ğŸ“„ Sample repository files:`, 
        repositoryFiles.slice(0, 3).map(f => ({
          name: f.file_name,
          hash: f.text_hash?.substring(0, 10) + '...',
          textLength: f.extracted_text?.length || 0,
        }))
      );
    }

    // Ø§Ù„Ø®Ø·ÙˆØ© 4: Ù…Ù‚Ø§Ø±Ù†Ø© ÙƒÙ„ Ù…Ù„Ù Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ ÙˆØ­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    for (const file of files) {
      const internalMatches = internalComparisons.get(file.fileHash) || [];
      const repositoryMatches = [];

      // Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
      if (repositoryFiles && repositoryFiles.length > 0) {
        const text1 = preprocessText(file.fileText, file.fileText.split(/\s+/).length);

        // âœ… Ø¥ØµÙ„Ø§Ø­ 5: ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Hash Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
        const exactHashMatch = repositoryFiles.find(rf => rf.text_hash === file.fileHash);
        if (exactHashMatch) {
          console.log(`ğŸ¯ EXACT HASH MATCH found in repository!`, {
            uploadedFile: file.fileName,
            matchedFile: exactHashMatch.file_name,
            hash: file.fileHash.substring(0, 10) + '...',
          });
          
          repositoryMatches.push({
            matched_file_id: exactHashMatch.id,
            matched_file_name: exactHashMatch.file_name,
            similarity_score: 1.0,
            similarity_method: 'hash_exact_match',
            flagged: true,
          });
        } else {
          // âœ… Ø¥ØµÙ„Ø§Ø­ 2: Ø¥Ø²Ø§Ù„Ø© Ø­Ø¯ Ø§Ù„Ù€ 10 Ù…Ù„ÙØ§Øª - Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
          for (const repoFile of repositoryFiles) {
          if (!repoFile.extracted_text) continue;

          const text2 = preprocessText(
            repoFile.extracted_text,
            repoFile.extracted_text.split(/\s+/).length
          );

          const similarity = calculateSimilarity(text1, text2);

          // âœ… Ø¥ØµÙ„Ø§Ø­ 6: Ø®ÙØ¶ Ø§Ù„Ø¹ØªØ¨Ø© Ù…Ù† 0.30 Ø¥Ù„Ù‰ 0.25 + Ø¥Ø¶Ø§ÙØ© logging
          if (similarity > 0.25) {
            // âœ… Ø¥ØµÙ„Ø§Ø­ 4: Ø¥Ø¶Ø§ÙØ© logging Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª
            if (similarity > 0.20) {
              console.log(`ğŸ” Match found: ${file.fileName} vs ${repoFile.file_name}`, {
                similarity: Math.round(similarity * 100) / 100,
                jaccard: calculateJaccard(text1.wordSet, text2.wordSet),
                repoFileHash: repoFile.text_hash?.substring(0, 10) + '...',
              });
            }
            
            repositoryMatches.push({
              matched_file_id: repoFile.id,
              matched_file_name: repoFile.file_name,
              similarity_score: Math.round(similarity * 100) / 100,
              similarity_method: 'text_comparison',
              flagged: similarity >= 0.70,
            });
          }
        }

        repositoryMatches.sort((a, b) => b.similarity_score - a.similarity_score);
        } // Ù†Ù‡Ø§ÙŠØ© else Ø§Ù„Ø®Ø§Øµ Ø¨ÙØ­Øµ Hash
      }

      // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
      const internalMaxSim = internalMatches.length > 0
        ? Math.max(...internalMatches.map(m => m.similarity_score))
        : 0;
      const internalHighRisk = internalMatches.filter(m => m.flagged).length;

      const repoMaxSim = repositoryMatches.length > 0
        ? Math.max(...repositoryMatches.map(m => m.similarity_score))
        : 0;
      const repoHighRisk = repositoryMatches.filter(m => m.flagged).length;

      const overallMaxSim = Math.max(internalMaxSim, repoMaxSim);
      
      let status = 'safe';
      if (overallMaxSim >= 0.70) status = 'flagged';
      else if (overallMaxSim >= 0.50) status = 'warning';

      const comparisonSource = 
        internalMatches.length > 0 && repositoryMatches.length > 0 ? 'both' :
        internalMatches.length > 0 ? 'internal' :
        'repository';

      // Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
      const result = {
        batch_id: batchId,
        compared_file_name: file.fileName,
        compared_file_path: file.filePath,
        compared_file_hash: file.fileHash,
        grade_level: gradeLevel,
        comparison_type: comparisonType,
        comparison_source: comparisonSource,
        
        // Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©
        internal_matches: internalMatches.slice(0, 5),
        internal_max_similarity: internalMaxSim,
        internal_high_risk_count: internalHighRisk,
        
        // Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
        repository_matches: repositoryMatches.slice(0, 5),
        repository_max_similarity: repoMaxSim,
        repository_high_risk_count: repoHighRisk,
        
        // Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        matches: [...internalMatches, ...repositoryMatches].slice(0, 5),
        max_similarity_score: overallMaxSim,
        total_matches_found: internalMatches.length + repositoryMatches.length,
        high_risk_matches: internalHighRisk + repoHighRisk,
        status,
        review_required: status === 'flagged',
        
        added_to_repository: true,
        repository_file_id: repositoryFileIds.get(file.fileHash),
        requested_by: userId,
        school_id: schoolId,
        processing_time_ms: Date.now() - startTime,
        algorithm_used: 'batch_comparison',
      };

      const { data: savedResult } = await supabase
        .from('pdf_comparison_results')
        .insert(result)
        .select()
        .single();

      if (savedResult) {
        results.push(savedResult);
        
        // ØªØ³Ø¬ÙŠÙ„ ÙÙŠ audit log
        await supabase.from('pdf_comparison_audit_log').insert({
          comparison_result_id: savedResult.id,
          action_type: 'batch_compare',
          performed_by: userId,
          details: {
            fileName: file.fileName,
            batchId,
            internalMatches: internalMatches.length,
            repositoryMatches: repositoryMatches.length,
            maxSimilarity: overallMaxSim,
            status,
          },
        });
      }
    }

    console.log(`âœ… Batch comparison completed in ${Date.now() - startTime}ms`);

    return new Response(
      JSON.stringify({ 
        success: true, 
        results,
        batchId,
        totalFiles: files.length,
        processingTime: Date.now() - startTime,
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  } catch (error) {
    console.error('Error in pdf-compare-batch function:', error);
    return new Response(
      JSON.stringify({
        success: false,
        error: error instanceof Error ? error.message : String(error),
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});

// Helper functions
function preprocessText(text: string, wordCount: number) {
  const normalized = normalizeArabicText(text);
  let words = normalized.split(/\s+/).filter(w => w.length > 2);
  
  const maxWords = 50000;
  if (words.length > maxWords) {
    const step = Math.floor(words.length / maxWords);
    words = words.filter((_, i) => i % step === 0).slice(0, maxWords);
  }
  
  const wordSet = new Set(words);
  return { normalized, words, wordSet };
}

function normalizeArabicText(text: string): string {
  return text
    .toLowerCase()
    .replace(/[Ù‹ÙŒÙÙÙÙÙ‘Ù’]/g, '')
    .replace(/[Ø¢Ø¥Ø£Ù±]/g, 'Ø§')
    .replace(/Ø©/g, 'Ù‡')
    .replace(/Ù‰/g, 'ÙŠ')
    .replace(/[^\w\s\u0600-\u06FF]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim();
}

function calculateSimilarity(text1: any, text2: any): number {
  // âœ… Ø¥ØµÙ„Ø§Ø­ 3: ØªØ­Ø³ÙŠÙ† Ø¯Ø§Ù„Ø© calculateSimilarity
  
  // 1. Jaccard Similarity (Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©)
  const jaccard = calculateJaccard(text1.wordSet, text2.wordSet);
  
  // 2. Fuzzy Similarity (Ø¹ÙŠÙ†Ø© Ø£ÙƒØ¨Ø± Ù…Ù† 5000 Ø¥Ù„Ù‰ 15000)
  const sampleSize = Math.min(
    15000,
    Math.min(text1.normalized.length, text2.normalized.length)
  );
  
  const sample1 = text1.normalized.substring(0, sampleSize);
  const sample2 = text2.normalized.substring(0, sampleSize);
  
  const fuzzy = fuzzball.ratio(sample1, sample2) / 100;
  
  // 3. Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¬Ù…Ù„ (Sentence-level similarity)
  const sentences1 = text1.normalized.split(/[.!?ØŸ]/);
  const sentences2 = text2.normalized.split(/[.!?ØŸ]/);
  
  let sentenceSimilarity = 0;
  if (sentences1.length > 0 && sentences2.length > 0) {
    const sentenceSet1 = new Set(sentences1.filter((s: string) => s.trim().length > 10));
    const sentenceSet2 = new Set(sentences2.filter((s: string) => s.trim().length > 10));
    sentenceSimilarity = calculateJaccard(sentenceSet1, sentenceSet2);
  }
  
  // 4. ÙˆØ²Ù† Ù…ØªÙˆØ§Ø²Ù†: Jaccard: 40%, Fuzzy: 40%, Sentence: 20%
  return (jaccard * 0.4 + fuzzy * 0.4 + sentenceSimilarity * 0.2);
}

function calculateJaccard(set1: Set<string>, set2: Set<string>): number {
  if (set1.size === 0 && set2.size === 0) return 0;
  
  let intersectionSize = 0;
  const smallerSet = set1.size < set2.size ? set1 : set2;
  const largerSet = set1.size < set2.size ? set2 : set1;
  
  for (const word of smallerSet) {
    if (largerSet.has(word)) intersectionSize++;
  }
  
  const unionSize = set1.size + set2.size - intersectionSize;
  return unionSize === 0 ? 0 : intersectionSize / unionSize;
}